{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "602b52f7-21a3-4976-a8f7-fe5f90572554",
      "metadata": {},
      "outputs": [],
      "source": [
        "<center>\n    <img src=\"https://cf-courses-data.s3.us.cloud-object-storage.appdomain.cloud/assets/logos/SN_web_lightmode.png\" width=\"300\" alt=\"cognitiveclass.ai logo\"  />\n</center>\n\n# **Heart Failure Prediction**\n\n# Lab 1. Dataset investigation\n\n# Abstract\nThe lab is designed to provide students with hands-on experience with a real heart failure prediction dataset and the tools needed for effective data manipulation and analysis. Here you will use Pandas to retrieve data, read data, rename columns, and save a dataset.\n\nEstimated time needed: **10** minutes\n\n## Objectives\n\nAfter completing this lab you will be able to:\n\n*   Acquire data in various ways\n*   Obtain insights from data with Pandas library\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "87764926-11df-4d8a-8760-bcbb5f02664a",
      "metadata": {},
      "outputs": [],
      "source": [
        "<h2>Table of Contents</h2>\n\n<div class=\"alert alert-block alert-info\" style=\"margin-top: 20px\">\n<ol>\n    <li><a href=\"#data_acquisition\">Data Acquisition</a>\n    <li><a href=\"#basic_insight\">Basic Insight of Dataset</a></li>\n</ol>\n\n</div>\n<hr>\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "8682eda9-f9bd-4b8a-ae37-adff64fa7301",
      "metadata": {},
      "outputs": [],
      "source": [
        "# 1. Data Acquisition <a id=\"data_acquisition\"></a>\n<p>\nThere are various formats for a dataset: .csv, .json, .xlsx  etc. The dataset can be stored in different places, on your local machine or sometimes online.<br>\n\nIn this section, you will learn how to load a dataset into our Jupyter Notebook.<br>\n\nIn our case, the Heart Failure Dataset is an online source, and it is in a CSV (comma separated value) format. Let's use this dataset as an example to practice data reading.\n\n    \nThe primary objective of the investigation is to develop a predictive model for estimating mortality resulting from Heart Failure. The dataset comprises comprehensive records of cardiac patients, collected from Institute of Cardiology, a hospital located in Faisalabad, Pakistan.\n    \n    \n<ul>\n    <li>Data source: <a href=\"https://www.kaggle.com/datasets/asgharalikhan/mortality-rate-heart-patient-pakistan-hospital\" target=\"_blank\">https://www.kaggle.com/datasets/asgharalikhan/mortality-rate-heart-patient-pakistan-hospital</a></li>\n    <li>Data type: csv</li>\n</ul>\nThe Pandas Library is a useful tool that enables us to read various datasets into a dataframe; our Jupyter notebook platforms have a built-in <b>Pandas Library</b> so that all we need to do is import Pandas without installing.\n</p>\n"
      ]
    },
    {
      "cell_type": "code",
      "id": "301a4225-9136-4feb-90df-7b4169c8161f",
      "metadata": {},
      "outputs": [],
      "source": [
        "#install specific version of libraries used in  lab\n#! mamba install pandas==1.3.3  -y\n#! mamba install numpy=1.21.2 -y"
      ]
    },
    {
      "cell_type": "code",
      "id": "e62dc3c5-459e-4bc9-9cd9-a414c72d0f39",
      "metadata": {},
      "outputs": [],
      "source": [
        "# import pandas library\nimport pandas as pd\nimport numpy as np"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "538ebd5f-d851-41b6-af97-4be872d6ea21",
      "metadata": {},
      "outputs": [],
      "source": [
        "<h2>Read Data</h2>\n<p>\nWe use <code>pandas.read_csv()</code> function to read the csv file. In the brackets, we put the file path along with a quotation mark so that pandas will read the file into a dataframe from that address. The file path can be either an URL or your local file address.<br>\n\nYou can also assign the dataset to any variable you create.\n\n</p>\n"
      ]
    },
    {
      "cell_type": "code",
      "id": "a7bd234a-4e8c-4cd2-aa41-c1bea123f3d3",
      "metadata": {},
      "outputs": [],
      "source": [
        "path = \"https://cf-courses-data.s3.us.cloud-object-storage.appdomain.cloud/IBMSkillsNetwork-GPXX0RS9EN/heart_failure_data.csv\""
      ]
    },
    {
      "cell_type": "code",
      "id": "4ad82a25-d6fc-4c85-8cb5-d7809fab4098",
      "metadata": {},
      "outputs": [],
      "source": [
        "# Read the online file by the URL provides above, and assign it to variable \"df\"\n\ndf = pd.read_csv(path)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ecca99ac-bbd6-4921-b83d-da6dd612015e",
      "metadata": {},
      "outputs": [],
      "source": [
        "After reading the dataset, we can use the <code>dataframe.head(n)</code> method to check the top n rows of the dataframe, where n is an integer. Contrary to <code>dataframe.head(n)</code>, <code>dataframe.tail(n)</code> will show you the bottom n rows of the dataframe.\n"
      ]
    },
    {
      "cell_type": "code",
      "id": "530bec65-a4a5-49e6-822f-553fdd3fd80f",
      "metadata": {},
      "outputs": [],
      "source": [
        "# show the first 5 rows using dataframe.head() method\nprint(\"The first 5 rows of the dataframe\") \ndf.head(5)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ceb67cc3-c41c-4a5b-ab83-dc5c1a59c4b2",
      "metadata": {},
      "outputs": [],
      "source": [
        "<div class=\"alert alert-danger alertdanger\" style=\"margin-top: 20px\">\n<h1> Question #1: </h1>\n<b>Check the bottom 10 rows of data frame \"df\".</b>\n</div>\n"
      ]
    },
    {
      "cell_type": "code",
      "id": "6380c697-5f4c-4fb0-ae4f-eb743ded1d3c",
      "metadata": {},
      "outputs": [],
      "source": [
        "# Write your code below and press Shift+Enter to execute\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "e272ff15-ee7c-4bd7-a4b3-f55e4ba0809b",
      "metadata": {},
      "outputs": [],
      "source": [
        "<details><summary>Click here for the solution</summary>\n\n```python\nprint(\"The last 10 rows of the dataframe\\n\")\ndf.tail(10)\n```\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "afa815dd-9a12-4832-b9d2-6e0f48ffb446",
      "metadata": {},
      "outputs": [],
      "source": [
        "<h3>Delete unnecessary columns</h3>\n<p>\nThis dataset has big number of columns. Some of them are unnecessary and incomprehensible. Let`s reduce this amount to simplify our future work with this dataset.\n</p>\n\nTo simplify our future work with this dataset, we can reduce the number of columns using three different approaches:\n\nThe DataFrame method called `drop()` allows us to remove rows or columns based on specific column labels and the corresponding axis.\n\nAnother option is to use the `del` keyword to delete a column. For example, we can delete a column using the syntax `del df['column name']`. In Python, this operation maps to `df.__delitem__('column name')`, which is an internal method of DataFrame.\n\nThe `pop()` function can also be used to drop a column. Unlike the previous methods, this function returns the dropped column as a separate object.\n<p>\nLet`s try the first one.\n</p>"
      ]
    },
    {
      "cell_type": "code",
      "id": "ade9e0df-2c3e-4172-a5b2-bc31be6e59d2",
      "metadata": {},
      "outputs": [],
      "source": [
        "columns = [\"F.History\", \"Family.History\", \"B.Urea\", \"S.Cr\", \"S.Sodium\", \"S.Potassium\", \"S.Chloride\"]\ndf = df.drop(columns = columns)\ndf"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "8c420608-6bbb-4040-a0f3-ee5d2a6f8d63",
      "metadata": {},
      "outputs": [],
      "source": [
        "<h3>Change Headers</h3>\n<p>\nTake a look at our dataset. Pandas automatically set the header with a first row of .csv file.\n</p>\n<p>\nTo better describe our data, we can introduce a header. This information is available at:  <a href=\"https://www.kaggle.com/datasets/asgharalikhan/mortality-rate-heart-patient-pakistan-hospital\" target=\"_blank\">https://www.kaggle.com/datasets/asgharalikhan/mortality-rate-heart-patient-pakistan-hospital</a>.\n</p>\n<p>\nThus, we can change headers of this dataset manually to make them look proper.\n</p>\n<p>\nFirst, we create a list \"headers\" that include all column names in order.\nThen, we use <code>dataframe.columns = headers</code> to replace the headers with the list we created.\n</p>\n"
      ]
    },
    {
      "cell_type": "code",
      "id": "cdc7d2b7-3e07-454f-80f4-40f6427d2b4e",
      "metadata": {},
      "outputs": [],
      "source": [
        "headers = [\"Age\", \"Age Group\", \"Gender\", \"Locality\", \"Marital Status\", \"Lifestyle\", \"Sleep\", \"Category\", \"Depression\",\n            \"Hyperlipidemia\", \"Smoking\", \"Diabetes\", \"HTN\", \"Allergies\", \"BP\", \"Thrombolysis\", \"BGR\", \"CPK\", \"CK-MB\",\n            \"ESR\", \"WBC\", \"RBC\", \"Hemoglobin\", \"PCV\", \"MCV\", \"MCH\", \"MCHC\", \"PlateletCount\", \"Neutrophil\",\n            \"Lymphocyte\", \"Monocyte\", \"Eosinophil\", \"Others\", \"CO\", \"Diagnosis\", \"Hypersensitivity\", \"Chest pain type\", \n            \"Resting BP\", \"Serum cholesterol\", \"FBS\", \"Resting electrocardiographic\", \"Max heart rate\", \"Angina\",\n            \"ST depression\", \"Slope\", \"Vessels num\", \"Thal\", \"Num\", \"Streptokinase\", \"SK React\", \"Reaction\",\n            \"Mortality\", \"Follow up\"]\nprint(\"headers\\n\", headers)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "b20856de-15ef-4287-9fcd-8904482ce154",
      "metadata": {},
      "outputs": [],
      "source": [
        "We replace headers and recheck our dataframe:\n"
      ]
    },
    {
      "cell_type": "code",
      "id": "cef924f7-4ae7-4340-bbb4-fa2c464d1c9f",
      "metadata": {},
      "outputs": [],
      "source": [
        "df.columns = headers\ndf.head(10)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ce13bfb8-22a9-4a0f-9129-4a72c83bec2e",
      "metadata": {},
      "outputs": [],
      "source": [
        "Now, we have successfully read the raw dataset and added the correct headers into the dataframe.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "0191b807-c4e4-441f-97ec-4f3e9837f6d2",
      "metadata": {},
      "outputs": [],
      "source": [
        " <div class=\"alert alert-danger alertdanger\" style=\"margin-top: 20px\">\n<h1> Question #2: </h1>\n<b>Find the name of the columns of the dataframe.</b>\n</div>\n"
      ]
    },
    {
      "cell_type": "code",
      "id": "6968b3d7-b8bb-47b2-8b5a-528e18b5b49f",
      "metadata": {},
      "outputs": [],
      "source": [
        "# Write your code below and press Shift+Enter to execute \n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "2cd753b5-2457-403a-a8eb-43530773880d",
      "metadata": {},
      "outputs": [],
      "source": [
        "<details><summary>Click here for the solution</summary>\n\n```python\nprint(df.columns)\n```\n\n</details>"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "fc8c9e4d-a390-49e1-a2aa-f75c13f08b9d",
      "metadata": {},
      "outputs": [],
      "source": [
        "<h2>Save Dataset</h2>\n<p>\nCorrespondingly, Pandas enables us to save the dataset to csv. By using the <code>dataframe.to_csv()</code> method, you can add the file path and name along with quotation marks in the brackets.\n</p>\n<p>\nFor example, if you would save the dataframe <b>df</b> as <b>heart_failure.csv</b> to your local machine, you may use the syntax below, where <code>index = False</code> means the row names will not be written.\n</p>\n"
      ]
    },
    {
      "cell_type": "raw",
      "id": "4315b796-6684-43cd-9122-2fcfbe776cdd",
      "metadata": {},
      "outputs": [],
      "source": [
        "df.to_csv(\"heart_failure.csv\", index=False)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "a80cca70-731e-4d91-97e0-e3b0884a0afb",
      "metadata": {},
      "outputs": [],
      "source": [
        "We can also read and save other file formats. We can use similar functions like **`pd.read_csv()`** and **`df.to_csv()`** for other data formats. The functions are listed in the following table:\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "a544253d-0464-4711-bb3f-f09f2982e627",
      "metadata": {},
      "outputs": [],
      "source": [
        "<h2>Read/Save Other Data Formats</h2>\n\n| Data Formate |        Read       |            Save |\n| ------------ | :---------------: | --------------: |\n| csv          |  `pd.read_csv()`  |   `df.to_csv()` |\n| json         |  `pd.read_json()` |  `df.to_json()` |\n| excel        | `pd.read_excel()` | `df.to_excel()` |\n| hdf          |  `pd.read_hdf()`  |   `df.to_hdf()` |\n| sql          |  `pd.read_sql()`  |   `df.to_sql()` |\n| ...          |        ...        |             ... |\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "267740ab-33a9-45e6-8e79-346719340310",
      "metadata": {},
      "outputs": [],
      "source": [
        "# 2. Basic Insight of Dataset <a id=\"basic_insight\"></a>\nAfter reading data into Pandas dataframe, it is time for us to explore the dataset.<br>\n\nThere are several ways to obtain essential insights of the data to help us better understand our dataset.\n\n</p>\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "97dda694-8835-4399-a30f-9092d0ae3d35",
      "metadata": {},
      "outputs": [],
      "source": [
        "<h2>Data Types</h2>\n<p>\nData has a variety of types.<br>\n\nThe main types stored in Pandas dataframes are <b>object</b>, <b>float</b>, <b>int</b>, <b>bool</b> and <b>datetime64</b>. In order to better learn about each attribute, it is always good for us to know the data type of each column. In Pandas:\n\n</p>\n"
      ]
    },
    {
      "cell_type": "code",
      "id": "aa70390f-a812-4033-8f69-d19dda56863d",
      "metadata": {},
      "outputs": [],
      "source": [
        "df.dtypes\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "faa82327-593d-46a2-8569-c21da2733810",
      "metadata": {},
      "outputs": [],
      "source": [
        "A series with the data type of each column is returned.\n"
      ]
    },
    {
      "cell_type": "code",
      "id": "84ed1761-a008-4cfb-9b9a-8bf5758bff90",
      "metadata": {},
      "outputs": [],
      "source": [
        "# check the data type of data frame \"df\" by .dtypes\nprint(df.dtypes)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "cf8c9cfc-45a4-4057-88fc-66eafa25ef74",
      "metadata": {},
      "outputs": [],
      "source": [
        "<p>\nAs shown above, it is clear to see that the data type of \"Age\" and \"Diabetes\" are <code>int64</code>, \"Gender\" and \"Locality\" are <code>object</code>, and \"BP\", \"RBC\" and \"Hemoglobin\" are <code>float64</code>, etc.\n</p>\n<p>\nThese data types can be changed. For example, we have some fields like \"Lifestyle\", \"Sleep\", \"Depression\", which are <code>object</code> instead of <code>bool</code>. We will learn how to fix it in a later module.\n</p>\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "985bbf8c-b5a2-43b2-a620-1200f125453e",
      "metadata": {},
      "outputs": [],
      "source": [
        "<h2>Describe</h2>\n\nIf we would like to get a statistical summary of each column e.g. count, column mean value, column standard deviation, etc., we use the describe method:\n"
      ]
    },
    {
      "cell_type": "raw",
      "id": "551d7ef3-b823-44b4-bd60-076357a01dae",
      "metadata": {},
      "outputs": [],
      "source": [
        "dataframe.describe()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "2e89875f-57fc-49e8-b769-8eafe1a62404",
      "metadata": {},
      "outputs": [],
      "source": [
        "This method will provide various summary statistics, excluding <code>NaN</code> (Not a Number) values.\n"
      ]
    },
    {
      "cell_type": "code",
      "id": "94e0a3ad-9d4e-4ea1-984c-c0a008f454e9",
      "metadata": {},
      "outputs": [],
      "source": [
        "df.describe()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ce634cf3-016d-4c1b-a50f-4670305f5b96",
      "metadata": {},
      "outputs": [],
      "source": [
        "<p>\nThis shows the statistical summary of all numeric-typed (int, float) columns.<br>\n\nFor example, the attribute \"BP\" (blood pressure) has 368 counts, the mean value of this column is 121.21, the standard deviation is 24.54, the minimum value is 80.5, 25th percentile is 100.7, 50th percentile is 120.8, 75th percentile is 140.7, and the maximum value is 190.11. <br>\n\nHowever, what if we would also like to check all the columns including those that are of type object? <br><br>\n\nYou can add an argument <code>include = \"all\"</code> inside the bracket. Let's try it again.\n\n</p>\n"
      ]
    },
    {
      "cell_type": "code",
      "id": "7d21767a-475a-4a08-a2d8-4f9be99dfdee",
      "metadata": {},
      "outputs": [],
      "source": [
        "# describe all the columns in \"df\" \ndf.describe(include = \"all\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "077a0dbf-2b3f-49a3-9b5e-de29ffd50550",
      "metadata": {},
      "outputs": [],
      "source": [
        "<p>\nNow it provides the statistical summary of all the columns, including object-typed attributes.<br>\n\nWe can now see how many unique values there, which one is the top value and the frequency of top value in the object-typed columns.<br>\n\nSome values in the table above show as \"NaN\". This is because those numbers are not available regarding a particular column type.<br>\n\nLet`s see what values are available for object-typed columns:\n\n</p>\n"
      ]
    },
    {
      "cell_type": "code",
      "id": "829d5676-4064-48cc-abde-0c964dff4b34",
      "metadata": {},
      "outputs": [],
      "source": [
        "# describe all the columns in \"df\"\ndf.describe(include = \"object\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "4dc0eb57-65ec-497c-86e0-a1799d565470",
      "metadata": {},
      "outputs": [],
      "source": [
        "<p>There are count, unique, top, freq values for object.</p>"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "d1cffee8-b4c7-43ad-af33-855d7f27c84a",
      "metadata": {},
      "outputs": [],
      "source": [
        "<div class=\"alert alert-danger alertdanger\" style=\"margin-top: 20px\">\n<h1> Question #3: </h1>\n\n<p>\nYou can select the columns of a dataframe by indicating the name of each column. For example, you can select the three columns as follows:\n</p>\n<p>\n    <code>dataframe[[' column 1 ',column 2', 'column 3']]</code>\n</p>\n<p>\nWhere \"column\" is the name of the column, you can apply the method  \".describe()\" to get the statistics of those columns as follows:\n</p>\n<p>\n    <code>dataframe[[' column 1 ',column 2', 'column 3'] ].describe()</code>\n</p>\n\nApply the  method to \".describe()\" to the columns 'Age' and 'BP'.\n\n</div>\n"
      ]
    },
    {
      "cell_type": "code",
      "id": "6b48ccdf-7ac8-4e0c-b810-17f5481c70d4",
      "metadata": {},
      "outputs": [],
      "source": [
        "# Write your code below and press Shift+Enter to execute \n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "f680eb05-770f-46e8-89bc-1cd61f67eb40",
      "metadata": {},
      "outputs": [],
      "source": [
        "<details><summary>Click here for the solution</summary>\n\n```python\ndf[['Age', 'BP']].describe()\n```\n\n</details>\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "4a7adcc9-7d42-40a4-a7eb-6d0c81ca73bb",
      "metadata": {},
      "outputs": [],
      "source": [
        "<h2>Info</h2>\nAnother method you can use to check your dataset is:\n"
      ]
    },
    {
      "cell_type": "raw",
      "id": "808be1f5-932e-4820-ad45-16ba0847d977",
      "metadata": {},
      "outputs": [],
      "source": [
        "dataframe.info()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "21ae1815-a23a-419d-9395-8974a2f80a34",
      "metadata": {},
      "outputs": [],
      "source": [
        "This method offers a compact overview of your DataFrame, presenting details such as the index data type, columns, non-null values, and memory usage. It provides information about the DataFrame's structure and memory consumption."
      ]
    },
    {
      "cell_type": "code",
      "id": "79164c99-93b0-4b5e-98d0-94e5e2b855ae",
      "metadata": {},
      "outputs": [],
      "source": [
        "# look at the info of \"df\"\ndf.info()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "9496646e-97a1-4b77-bd00-d27d370fe282",
      "metadata": {},
      "outputs": [],
      "source": [
        "<h1>Excellent! You have just completed the  Introduction Notebook!</h1>\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "4c56eb5c-948f-4ac0-ab13-cadfa6bc6a79",
      "metadata": {},
      "outputs": [],
      "source": [
        "### Thank you for completing this lab!\n\n## Author\n\n<a href=\"https://author.skills.network/instructors/bohdan_kuno\">Bohdan Kuno</a>\n\n### Other Contributors\n\n<a href=\"https://author.skills.network/instructors/yaroslav_vyklyuk_2\">Prof. Yaroslav Vyklyuk, DrSc, PhD</a>\n\n<a href=\"https://author.skills.network/instructors/nataliya_boyko\">Ass. Prof. Nataliya Boyko, PhD</a>\n\n\n## Change Log\n\n| Date (YYYY-MM-DD) | Version | Changed By | Change Description                                         |\n| ----------------- | ------- | ---------- | ---------------------------------------------------------- |\n|2023-02-25|01|Bohdan Kuno|Lab created|\n\n\n<hr>\n\n## <h3 align=\"center\"> Â© IBM Corporation 2023. All rights reserved. <h3/>\n"
      ]
    }
  ],
  "metadata": {
    "language_info": {
      "name": ""
    },
    "kernelspec": {
      "name": "",
      "display_name": ""
    }
  },
  "nbformat": 4,
  "nbformat_minor": 4
}